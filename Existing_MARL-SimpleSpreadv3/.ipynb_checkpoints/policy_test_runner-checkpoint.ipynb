{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94cc53-d7ff-43e9-994e-d31181ff5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from pettingzoo.mpe import simple_spread_v3\n",
    "from train import DQN\n",
    "\n",
    "\n",
    "# Action definitions\n",
    "NOTHING = 0\n",
    "LEFT = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "UP = 4\n",
    "\n",
    "\n",
    "class DQLPolicy:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        input_shape = 18\n",
    "        output_actions = 5\n",
    "        self.model = DQN(input_shape, output_actions)\n",
    "        self.model.load_state_dict(torch.load(f\"models/{self.agent}.pt\"))\n",
    "        self.model.eval()\n",
    "\n",
    "    def choose_action(self, observations):\n",
    "        obs_tensor = torch.from_numpy(observations[self.agent]).float()\n",
    "        with torch.no_grad():\n",
    "            return self.model(obs_tensor).argmax().item()\n",
    "\n",
    "\n",
    "def test_rl_policy(num_of_runs=5, seeds=None, max_cycles=25, local_ratio=0.5):\n",
    "    env = simple_spread_v3.parallel_env(\n",
    "        render_mode=\"human\",\n",
    "        local_ratio=local_ratio,\n",
    "        max_cycles=max_cycles\n",
    "    )\n",
    "\n",
    "    agents = [f\"agent_{i}\" for i in range(3)]\n",
    "    policies = {agent: DQLPolicy(agent) for agent in agents}\n",
    "\n",
    "    for run in range(num_of_runs):\n",
    "        seed = seeds[run] if seeds and run < len(seeds) else random.randint(0, 1000)\n",
    "        observations, _ = env.reset(seed=seed)\n",
    "\n",
    "        avg_rewards = {agent: 0 for agent in agents}\n",
    "        actions = {agent: 0 for agent in agents}\n",
    "\n",
    "        while env.agents:\n",
    "            for agent in env.agents:\n",
    "                actions[agent] = policies[agent].choose_action(observations)\n",
    "            observations, rewards, _, _, _ = env.step(actions)\n",
    "            for agent in env.agents:\n",
    "                avg_rewards[agent] += rewards[agent] / max_cycles\n",
    "\n",
    "        print(f\"[Seed {seed}] Average Rewards: \" + \", \".join([f\"{a}: {avg_rewards[a]:.2f}\" for a in agents]))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example use: run 3 evaluations with fixed seeds\n",
    "    test_rl_policy(num_of_runs=3, seeds=[42, 7, 123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a1b73-06cc-477e-ac3b-e1de9361b8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3b8ac-f446-4154-8560-e3a2e27f1101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d52bbdb-159d-421c-83b0-3e4f62758285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies: ['rl', 'rl', 'rl']\n",
      "Runs: 3\n",
      "Seeds: [73, 45, 24]\n",
      "AVERAGE REWARDS [73]: {'agent_0': -0.91, 'agent_1': -0.91, 'agent_2': -0.91}\n",
      "FINAL REWARDS   [73]: {'agent_0': -0.98, 'agent_1': -0.98, 'agent_2': -0.98}\n",
      "\n",
      "AVERAGE REWARDS [45]: {'agent_0': -0.48, 'agent_1': -0.48, 'agent_2': -0.4}\n",
      "FINAL REWARDS   [45]: {'agent_0': -0.43, 'agent_1': -0.43, 'agent_2': -0.43}\n",
      "\n",
      "AVERAGE REWARDS [24]: {'agent_0': -0.72, 'agent_1': -0.74, 'agent_2': -0.74}\n",
      "FINAL REWARDS   [24]: {'agent_0': -1.0, 'agent_1': -1.0, 'agent_2': -1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from evaluation.evaluator import test\n",
    "\n",
    "# Cell 2: Define policies and run test\n",
    "policies = [\"rl\", \"rl\", \"rl\"]  # All agents use trained RL models\n",
    "num_of_runs = 3\n",
    "seeds = [73, 45, 24]  # or: None\n",
    "\n",
    "test(policies, num_of_runs, seeds, DEBUG=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7415ce-079c-43e6-9b1f-b7be60dbb664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab42727-257c-4c2e-90b4-5af8bb51fa1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2888d-12c6-446f-b21b-5ab789bed97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddbf940-21b1-42c8-8d6d-204e63256ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies: ['rl', 'sp', 'cp']\n",
      "Runs: 3\n",
      "Seeds: [42, 1337, 7]\n",
      "AVERAGE REWARDS [42]: {'agent_0': -0.63, 'agent_1': -0.63, 'agent_2': -0.63}\n",
      "FINAL REWARDS   [42]: {'agent_0': -0.48, 'agent_1': -0.48, 'agent_2': -0.48}\n",
      "\n",
      "AVERAGE REWARDS [1337]: {'agent_0': -1.14, 'agent_1': -1.12, 'agent_2': -1.14}\n",
      "FINAL REWARDS   [1337]: {'agent_0': -0.54, 'agent_1': -0.54, 'agent_2': -0.54}\n",
      "\n",
      "AVERAGE REWARDS [7]: {'agent_0': -0.71, 'agent_1': -0.71, 'agent_2': -0.71}\n",
      "FINAL REWARDS   [7]: {'agent_0': -0.64, 'agent_1': -0.64, 'agent_2': -0.64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from evaluation.evaluator import test\n",
    "\n",
    "# Cell 2: Run Tests\n",
    "# Options: \"rl\" (Reinforcement Learning), \"sp\" (Simple Policy), \"cp\" (Complex Policy)\n",
    "policies = [\"rl\", \"sp\", \"cp\"]  # agent_0 uses RL, agent_1 simple, agent_2 complex\n",
    "num_of_runs = 3\n",
    "seeds = [42, 1337, 7]  # optional, or use: seeds = None\n",
    "\n",
    "test(policies, num_of_runs, seeds, DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f644d59f-b44c-439a-80a4-36ba3edb3751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies: ['sp', 'sp', 'sp']\n",
      "Runs: 3\n",
      "Seeds: [69, 85, 10]\n",
      "AVERAGE REWARDS [69]: {'agent_0': -0.75, 'agent_1': -0.89, 'agent_2': -0.89}\n",
      "FINAL REWARDS   [69]: {'agent_0': -0.83, 'agent_1': -0.83, 'agent_2': -0.83}\n",
      "\n",
      "AVERAGE REWARDS [85]: {'agent_0': -0.46, 'agent_1': -0.56, 'agent_2': -0.42}\n",
      "FINAL REWARDS   [85]: {'agent_0': -0.15, 'agent_1': -0.15, 'agent_2': -0.15}\n",
      "\n",
      "AVERAGE REWARDS [10]: {'agent_0': -1.22, 'agent_1': -1.18, 'agent_2': -1.1}\n",
      "FINAL REWARDS   [10]: {'agent_0': -0.4, 'agent_1': -0.4, 'agent_2': -0.4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from evaluation.evaluator import test\n",
    "\n",
    "# Cell 2: Define policies and run test\n",
    "policies = [\"sp\", \"sp\", \"sp\"]  # All agents use simple hand-coded policy\n",
    "num_of_runs = 3\n",
    "seeds = [69, 85, 10]  # or: None\n",
    "\n",
    "test(policies, num_of_runs, seeds, DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaae7c4e-62ba-44d8-8671-a2a65ab9f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies: ['cp', 'cp', 'cp']\n",
      "Runs: 3\n",
      "Seeds: [40, 21, 88]\n",
      "AVERAGE REWARDS [40]: {'agent_0': -0.58, 'agent_1': -0.58, 'agent_2': -0.58}\n",
      "FINAL REWARDS   [40]: {'agent_0': -0.34, 'agent_1': -0.34, 'agent_2': -0.34}\n",
      "\n",
      "AVERAGE REWARDS [21]: {'agent_0': -0.41, 'agent_1': -0.41, 'agent_2': -0.41}\n",
      "FINAL REWARDS   [21]: {'agent_0': -0.26, 'agent_1': -0.26, 'agent_2': -0.26}\n",
      "\n",
      "AVERAGE REWARDS [88]: {'agent_0': -0.5, 'agent_1': -0.44, 'agent_2': -0.5}\n",
      "FINAL REWARDS   [88]: {'agent_0': -0.35, 'agent_1': -0.35, 'agent_2': -0.35}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from evaluation.evaluator import test\n",
    "\n",
    "# Cell 2: Define policies and run test\n",
    "policies = [\"cp\", \"cp\", \"cp\"]  # All agents use coordination-based complex policy\n",
    "num_of_runs = 3\n",
    "seeds = [40, 21, 88]  # or: None\n",
    "\n",
    "test(policies, num_of_runs, seeds, DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b8574-4d11-46f1-bc5d-a40d0bdb452b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
